{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875e7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith torch.no_grad():\\n    net.eval()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네트워크 테스트하는 함수 구현하기\n",
    "\n",
    "# MNIST 데이터셋 불러오는 부분에서 train = True -> False로 변환\n",
    "'''\n",
    "dataset = datasets.MNIST(download=True, root='./', train=False, transform = transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "'''\n",
    "\n",
    "# 트레이닝 시작 부분에서 아래 코드 삭제 후 \n",
    "'''\n",
    "for epoch in range(1, num_epoch + 1) :\n",
    "    net.train()\n",
    "'''\n",
    "\n",
    "'''\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c758df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3bf211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에 필요한 parameter 설정하기\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "num_epoch = 10\n",
    "\n",
    "# 학습된 data가 저장될 dir\n",
    "ckpt_dir = './checkpoint'\n",
    "# tensorboard가 저장될 dir\n",
    "log_dir = './log'\n",
    "# device 정보 입력\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77382902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier network 구축\n",
    "\n",
    "class Net(nn.Module) :\n",
    "    # Layer 초기화 단계\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=320, out_features=50, bias=True)\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "        self.drop1_fc1 = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "        \n",
    "        \n",
    "    # Layer 구축 단계\n",
    "    def forward(self,x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "    \n",
    "        \n",
    "        x = x.view(-1, 320)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "        x = self.drop1_fc1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca08636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크를 저장하거나 불러오는 함수 (save(), load())\n",
    "\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "               './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n",
    "\n",
    "def load(ckpt_dir, net, optim):\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort()\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee1f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 셋 불러오기\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "dataset = datasets.MNIST(download=True, root='./', train=False, transform = transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "num_data = len(loader.dataset)\n",
    "num_batch = np.ceil(num_data / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa61d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 설정 및 손실함수 설정하기\n",
    "net = Net().to(device)\n",
    "params = net.parameters()\n",
    "\n",
    "fn_loss = nn.CrossEntropyLoss().to(device)\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "optim = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "net, optim = load(ckpt_dir=ckpt_dir, net=net, optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deef8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blue/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: BATCH 0001/0157 | LOSS 0.0210 | ACC 1.0000\n",
      "TEST: BATCH 0002/0157 | LOSS 0.0169 | ACC 1.0000\n",
      "TEST: BATCH 0003/0157 | LOSS 0.0153 | ACC 1.0000\n",
      "TEST: BATCH 0004/0157 | LOSS 0.0209 | ACC 0.9961\n",
      "TEST: BATCH 0005/0157 | LOSS 0.0257 | ACC 0.9938\n",
      "TEST: BATCH 0006/0157 | LOSS 0.0286 | ACC 0.9922\n",
      "TEST: BATCH 0007/0157 | LOSS 0.0339 | ACC 0.9911\n",
      "TEST: BATCH 0008/0157 | LOSS 0.0363 | ACC 0.9902\n",
      "TEST: BATCH 0009/0157 | LOSS 0.0335 | ACC 0.9913\n",
      "TEST: BATCH 0010/0157 | LOSS 0.0327 | ACC 0.9922\n",
      "TEST: BATCH 0011/0157 | LOSS 0.0322 | ACC 0.9929\n",
      "TEST: BATCH 0012/0157 | LOSS 0.0359 | ACC 0.9909\n",
      "TEST: BATCH 0013/0157 | LOSS 0.0352 | ACC 0.9904\n",
      "TEST: BATCH 0014/0157 | LOSS 0.0337 | ACC 0.9911\n",
      "TEST: BATCH 0015/0157 | LOSS 0.0363 | ACC 0.9896\n",
      "TEST: BATCH 0016/0157 | LOSS 0.0403 | ACC 0.9883\n",
      "TEST: BATCH 0017/0157 | LOSS 0.0413 | ACC 0.9881\n",
      "TEST: BATCH 0018/0157 | LOSS 0.0402 | ACC 0.9887\n",
      "TEST: BATCH 0019/0157 | LOSS 0.0393 | ACC 0.9893\n",
      "TEST: BATCH 0020/0157 | LOSS 0.0449 | ACC 0.9875\n",
      "TEST: BATCH 0021/0157 | LOSS 0.0487 | ACC 0.9866\n",
      "TEST: BATCH 0022/0157 | LOSS 0.0474 | ACC 0.9872\n",
      "TEST: BATCH 0023/0157 | LOSS 0.0468 | ACC 0.9871\n",
      "TEST: BATCH 0024/0157 | LOSS 0.0481 | ACC 0.9857\n",
      "TEST: BATCH 0025/0157 | LOSS 0.0478 | ACC 0.9856\n",
      "TEST: BATCH 0026/0157 | LOSS 0.0493 | ACC 0.9856\n",
      "TEST: BATCH 0027/0157 | LOSS 0.0529 | ACC 0.9844\n",
      "TEST: BATCH 0028/0157 | LOSS 0.0540 | ACC 0.9838\n",
      "TEST: BATCH 0029/0157 | LOSS 0.0524 | ACC 0.9844\n",
      "TEST: BATCH 0030/0157 | LOSS 0.0530 | ACC 0.9839\n",
      "TEST: BATCH 0031/0157 | LOSS 0.0515 | ACC 0.9844\n",
      "TEST: BATCH 0032/0157 | LOSS 0.0532 | ACC 0.9834\n",
      "TEST: BATCH 0033/0157 | LOSS 0.0529 | ACC 0.9834\n",
      "TEST: BATCH 0034/0157 | LOSS 0.0535 | ACC 0.9825\n",
      "TEST: BATCH 0035/0157 | LOSS 0.0538 | ACC 0.9821\n",
      "TEST: BATCH 0036/0157 | LOSS 0.0537 | ACC 0.9822\n",
      "TEST: BATCH 0037/0157 | LOSS 0.0528 | ACC 0.9827\n",
      "TEST: BATCH 0038/0157 | LOSS 0.0532 | ACC 0.9827\n",
      "TEST: BATCH 0039/0157 | LOSS 0.0526 | ACC 0.9828\n",
      "TEST: BATCH 0040/0157 | LOSS 0.0514 | ACC 0.9832\n",
      "TEST: BATCH 0041/0157 | LOSS 0.0530 | ACC 0.9832\n",
      "TEST: BATCH 0042/0157 | LOSS 0.0557 | ACC 0.9833\n",
      "TEST: BATCH 0043/0157 | LOSS 0.0551 | ACC 0.9836\n",
      "TEST: BATCH 0044/0157 | LOSS 0.0541 | ACC 0.9840\n",
      "TEST: BATCH 0045/0157 | LOSS 0.0531 | ACC 0.9844\n",
      "TEST: BATCH 0046/0157 | LOSS 0.0543 | ACC 0.9837\n",
      "TEST: BATCH 0047/0157 | LOSS 0.0546 | ACC 0.9830\n",
      "TEST: BATCH 0048/0157 | LOSS 0.0540 | ACC 0.9834\n",
      "TEST: BATCH 0049/0157 | LOSS 0.0538 | ACC 0.9834\n",
      "TEST: BATCH 0050/0157 | LOSS 0.0530 | ACC 0.9838\n",
      "TEST: BATCH 0051/0157 | LOSS 0.0522 | ACC 0.9841\n",
      "TEST: BATCH 0052/0157 | LOSS 0.0518 | ACC 0.9841\n",
      "TEST: BATCH 0053/0157 | LOSS 0.0512 | ACC 0.9844\n",
      "TEST: BATCH 0054/0157 | LOSS 0.0512 | ACC 0.9844\n",
      "TEST: BATCH 0055/0157 | LOSS 0.0509 | ACC 0.9844\n",
      "TEST: BATCH 0056/0157 | LOSS 0.0544 | ACC 0.9841\n",
      "TEST: BATCH 0057/0157 | LOSS 0.0545 | ACC 0.9838\n",
      "TEST: BATCH 0058/0157 | LOSS 0.0537 | ACC 0.9841\n",
      "TEST: BATCH 0059/0157 | LOSS 0.0557 | ACC 0.9838\n",
      "TEST: BATCH 0060/0157 | LOSS 0.0575 | ACC 0.9833\n",
      "TEST: BATCH 0061/0157 | LOSS 0.0587 | ACC 0.9828\n",
      "TEST: BATCH 0062/0157 | LOSS 0.0590 | ACC 0.9826\n",
      "TEST: BATCH 0063/0157 | LOSS 0.0592 | ACC 0.9824\n",
      "TEST: BATCH 0064/0157 | LOSS 0.0591 | ACC 0.9824\n",
      "TEST: BATCH 0065/0157 | LOSS 0.0583 | ACC 0.9827\n",
      "TEST: BATCH 0066/0157 | LOSS 0.0590 | ACC 0.9820\n",
      "TEST: BATCH 0067/0157 | LOSS 0.0590 | ACC 0.9820\n",
      "TEST: BATCH 0068/0157 | LOSS 0.0585 | ACC 0.9823\n",
      "TEST: BATCH 0069/0157 | LOSS 0.0581 | ACC 0.9823\n",
      "TEST: BATCH 0070/0157 | LOSS 0.0575 | ACC 0.9826\n",
      "TEST: BATCH 0071/0157 | LOSS 0.0576 | ACC 0.9824\n",
      "TEST: BATCH 0072/0157 | LOSS 0.0571 | ACC 0.9826\n",
      "TEST: BATCH 0073/0157 | LOSS 0.0573 | ACC 0.9827\n",
      "TEST: BATCH 0074/0157 | LOSS 0.0569 | ACC 0.9827\n",
      "TEST: BATCH 0075/0157 | LOSS 0.0571 | ACC 0.9825\n",
      "TEST: BATCH 0076/0157 | LOSS 0.0572 | ACC 0.9823\n",
      "TEST: BATCH 0077/0157 | LOSS 0.0575 | ACC 0.9823\n",
      "TEST: BATCH 0078/0157 | LOSS 0.0570 | ACC 0.9826\n",
      "TEST: BATCH 0079/0157 | LOSS 0.0562 | ACC 0.9828\n",
      "TEST: BATCH 0080/0157 | LOSS 0.0555 | ACC 0.9830\n",
      "TEST: BATCH 0081/0157 | LOSS 0.0549 | ACC 0.9832\n",
      "TEST: BATCH 0082/0157 | LOSS 0.0542 | ACC 0.9834\n",
      "TEST: BATCH 0083/0157 | LOSS 0.0536 | ACC 0.9836\n",
      "TEST: BATCH 0084/0157 | LOSS 0.0530 | ACC 0.9838\n",
      "TEST: BATCH 0085/0157 | LOSS 0.0523 | ACC 0.9840\n",
      "TEST: BATCH 0086/0157 | LOSS 0.0517 | ACC 0.9842\n",
      "TEST: BATCH 0087/0157 | LOSS 0.0512 | ACC 0.9844\n",
      "TEST: BATCH 0088/0157 | LOSS 0.0509 | ACC 0.9844\n",
      "TEST: BATCH 0089/0157 | LOSS 0.0503 | ACC 0.9846\n",
      "TEST: BATCH 0090/0157 | LOSS 0.0500 | ACC 0.9847\n",
      "TEST: BATCH 0091/0157 | LOSS 0.0494 | ACC 0.9849\n",
      "TEST: BATCH 0092/0157 | LOSS 0.0496 | ACC 0.9845\n",
      "TEST: BATCH 0093/0157 | LOSS 0.0497 | ACC 0.9845\n",
      "TEST: BATCH 0094/0157 | LOSS 0.0503 | ACC 0.9842\n",
      "TEST: BATCH 0095/0157 | LOSS 0.0501 | ACC 0.9842\n",
      "TEST: BATCH 0096/0157 | LOSS 0.0496 | ACC 0.9844\n",
      "TEST: BATCH 0097/0157 | LOSS 0.0491 | ACC 0.9845\n",
      "TEST: BATCH 0098/0157 | LOSS 0.0486 | ACC 0.9847\n",
      "TEST: BATCH 0099/0157 | LOSS 0.0481 | ACC 0.9848\n",
      "TEST: BATCH 0100/0157 | LOSS 0.0477 | ACC 0.9850\n",
      "TEST: BATCH 0101/0157 | LOSS 0.0472 | ACC 0.9851\n",
      "TEST: BATCH 0102/0157 | LOSS 0.0478 | ACC 0.9851\n",
      "TEST: BATCH 0103/0157 | LOSS 0.0490 | ACC 0.9847\n",
      "TEST: BATCH 0104/0157 | LOSS 0.0497 | ACC 0.9842\n",
      "TEST: BATCH 0105/0157 | LOSS 0.0493 | ACC 0.9844\n",
      "TEST: BATCH 0106/0157 | LOSS 0.0489 | ACC 0.9845\n",
      "TEST: BATCH 0107/0157 | LOSS 0.0485 | ACC 0.9847\n",
      "TEST: BATCH 0108/0157 | LOSS 0.0481 | ACC 0.9848\n",
      "TEST: BATCH 0109/0157 | LOSS 0.0476 | ACC 0.9849\n",
      "TEST: BATCH 0110/0157 | LOSS 0.0472 | ACC 0.9851\n",
      "TEST: BATCH 0111/0157 | LOSS 0.0468 | ACC 0.9852\n",
      "TEST: BATCH 0112/0157 | LOSS 0.0464 | ACC 0.9854\n",
      "TEST: BATCH 0113/0157 | LOSS 0.0461 | ACC 0.9855\n",
      "TEST: BATCH 0114/0157 | LOSS 0.0457 | ACC 0.9856\n",
      "TEST: BATCH 0115/0157 | LOSS 0.0454 | ACC 0.9857\n",
      "TEST: BATCH 0116/0157 | LOSS 0.0450 | ACC 0.9859\n",
      "TEST: BATCH 0117/0157 | LOSS 0.0450 | ACC 0.9858\n",
      "TEST: BATCH 0118/0157 | LOSS 0.0447 | ACC 0.9860\n",
      "TEST: BATCH 0119/0157 | LOSS 0.0444 | ACC 0.9861\n",
      "TEST: BATCH 0120/0157 | LOSS 0.0441 | ACC 0.9862\n",
      "TEST: BATCH 0121/0157 | LOSS 0.0437 | ACC 0.9863\n",
      "TEST: BATCH 0122/0157 | LOSS 0.0435 | ACC 0.9864\n",
      "TEST: BATCH 0123/0157 | LOSS 0.0435 | ACC 0.9864\n",
      "TEST: BATCH 0124/0157 | LOSS 0.0432 | ACC 0.9865\n",
      "TEST: BATCH 0125/0157 | LOSS 0.0428 | ACC 0.9866\n",
      "TEST: BATCH 0126/0157 | LOSS 0.0425 | ACC 0.9867\n",
      "TEST: BATCH 0127/0157 | LOSS 0.0431 | ACC 0.9867\n",
      "TEST: BATCH 0128/0157 | LOSS 0.0428 | ACC 0.9868\n",
      "TEST: BATCH 0129/0157 | LOSS 0.0425 | ACC 0.9869\n",
      "TEST: BATCH 0130/0157 | LOSS 0.0423 | ACC 0.9869\n",
      "TEST: BATCH 0131/0157 | LOSS 0.0420 | ACC 0.9870\n",
      "TEST: BATCH 0132/0157 | LOSS 0.0418 | ACC 0.9871\n",
      "TEST: BATCH 0133/0157 | LOSS 0.0415 | ACC 0.9872\n",
      "TEST: BATCH 0134/0157 | LOSS 0.0413 | ACC 0.9872\n",
      "TEST: BATCH 0135/0157 | LOSS 0.0410 | ACC 0.9873\n",
      "TEST: BATCH 0136/0157 | LOSS 0.0407 | ACC 0.9874\n",
      "TEST: BATCH 0137/0157 | LOSS 0.0404 | ACC 0.9875\n",
      "TEST: BATCH 0138/0157 | LOSS 0.0401 | ACC 0.9875\n",
      "TEST: BATCH 0139/0157 | LOSS 0.0398 | ACC 0.9876\n",
      "TEST: BATCH 0140/0157 | LOSS 0.0396 | ACC 0.9877\n",
      "TEST: BATCH 0141/0157 | LOSS 0.0407 | ACC 0.9875\n",
      "TEST: BATCH 0142/0157 | LOSS 0.0411 | ACC 0.9873\n",
      "TEST: BATCH 0143/0157 | LOSS 0.0408 | ACC 0.9874\n",
      "TEST: BATCH 0144/0157 | LOSS 0.0405 | ACC 0.9875\n",
      "TEST: BATCH 0145/0157 | LOSS 0.0402 | ACC 0.9876\n",
      "TEST: BATCH 0146/0157 | LOSS 0.0400 | ACC 0.9877\n",
      "TEST: BATCH 0147/0157 | LOSS 0.0397 | ACC 0.9878\n",
      "TEST: BATCH 0148/0157 | LOSS 0.0394 | ACC 0.9879\n",
      "TEST: BATCH 0149/0157 | LOSS 0.0392 | ACC 0.9879\n",
      "TEST: BATCH 0150/0157 | LOSS 0.0390 | ACC 0.9880\n",
      "TEST: BATCH 0151/0157 | LOSS 0.0393 | ACC 0.9879\n",
      "TEST: BATCH 0152/0157 | LOSS 0.0395 | ACC 0.9878\n",
      "TEST: BATCH 0153/0157 | LOSS 0.0404 | ACC 0.9875\n",
      "TEST: BATCH 0154/0157 | LOSS 0.0402 | ACC 0.9876\n",
      "TEST: BATCH 0155/0157 | LOSS 0.0406 | ACC 0.9875\n",
      "TEST: BATCH 0156/0157 | LOSS 0.0406 | ACC 0.9876\n",
      "TEST: BATCH 0157/0157 | LOSS 0.0403 | ACC 0.9877\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 학습을 위한 for문 구현 (트레이닝 시작)\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    \n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    \n",
    "    for batch, (input, label) in enumerate(loader, 1) :\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = net(input)\n",
    "        pred = fn_pred(output)\n",
    "        \n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss = fn_loss(output, label)\n",
    "        acc = fn_acc(pred, label)\n",
    "        \n",
    "        #loss.backward()\n",
    "        \n",
    "        #optim.step()\n",
    "        \n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "        \n",
    "        print('TEST: BATCH %04d/%04d | LOSS %.4f | ACC %.4f' % \n",
    "              (batch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))\n",
    "\n",
    "    #writer.add_scalar('loss', np.mean(loss_arr),epoch)\n",
    "    #writer.add_scalar('loss', np.mean(acc_arr),epoch)\n",
    "    \n",
    "    #save(ckpt_dir = ckpt_dir, net =net, optim = optim, epoch = epoch)\n",
    "\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ebacca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d67eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4675469b3c6736aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4675469b3c6736aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir='~/Desktop/Daeheon/conda/Deeplearning/MNIST/log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184a4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
