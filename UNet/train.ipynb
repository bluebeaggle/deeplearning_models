{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa18ac7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T15:17:13.248340Z",
     "start_time": "2023-05-02T15:17:11.619970Z"
    }
   },
   "outputs": [],
   "source": [
    "## 라이브러리 추가하기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30209cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T15:17:13.251642Z",
     "start_time": "2023-05-02T15:17:13.249762Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper parameter 설정\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "\n",
    "data_dir = './datasets'\n",
    "ckpt_dir = './checkpoint'   #train된 Network가 저장될 dir\n",
    "log_dir = './log'           #tensorboard의 로그가 기록될 dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24e8ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T15:17:13.263011Z",
     "start_time": "2023-05-02T15:17:13.252475Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7e4f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T15:17:13.285238Z",
     "start_time": "2023-05-02T15:17:13.263844Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## 네트워크 학습하기\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "\n",
    "dataset_test = Dataset(data_dir=os.path.join(data_dir, 'test'), transform=transform)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "dataset_val = Dataset(data_dir=os.path.join(data_dir, 'val'), transform=transform)\n",
    "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "## 네트워크 생성하기\n",
    "net = UNet().to(device)\n",
    "\n",
    "## 손실함수 정의하기\n",
    "fn_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "## Optimizer 설정하기\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "## 그밖에 부수적인 variables 설정하기\n",
    "num_data_test = len(dataset_test)\n",
    "num_data_val = len(num_data_val)\n",
    "\n",
    "num_batch_train = np.ceil(num_data_test / batch_size)\n",
    "num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "\n",
    "## 그밖에 부수적인 functions 설정하기\n",
    "# tensor variable에서 Numpy로 변환시키는 함수\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
    "# normalization 되어있는 data를 반대로 de-normalization 하는 함수\n",
    "fn_denorm = lambda x, mean, std: (x * std) + mean\n",
    "# 네트워크 아웃풋 이미지를 bin 클래스로 분류해주는 함수\n",
    "fn_class = lambda x: 1.0 * (x > 0.5)\n",
    "\n",
    "# 텐서보드를 사용하기 위한 summaryWriter 설정\n",
    "writer_train = SummaryWriter(log_dir=os.path.join(log_dir, 'train'))\n",
    "writer_val = SummaryWriter(log_dir=os.path.join(log_dir, 'val'))\n",
    "           \n",
    "## 네트워크 저장하기\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "               \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
    "\n",
    "## 네트워크 불러오기\n",
    "st_epoch = 0\n",
    "\n",
    "def load(ckpt_dir, net, optim):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "\n",
    "    return net, optim, epoch\n",
    "\n",
    "# train을 진행시키는 반복문\n",
    "st_epoch = 0\n",
    "# 학습 이전에, 저장되어있는 network가 있다면 불러와서 연속적으로 학습할 수 있도록 load 해줌\n",
    "net, optim, st_epoch = load(chkpt_dir=ckpt_dir, net=net, optim=optim )\n",
    "\n",
    "for epoch in range(st_epoch + 1, num_epoch + 1) :\n",
    "    net.train()\n",
    "    loss_arr = []\n",
    "    \n",
    "    for batch, data in enumerate(loader_test, 1):\n",
    "        # forward pass\n",
    "        # Netword의 input을 받아 Output을 출력\n",
    "        label = data['label'].to(device)\n",
    "        input = data['input'].to(device)\n",
    "        \n",
    "        # backward\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        loss = fn_loss(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        # 손실함수 계산\n",
    "        loss_arr += [loss.item()]\n",
    "        print(\"TRAIN: EPOCH %04d / %04d BATCH %04d / %04d| LOSS %.4f\" %\n",
    "                (epoch,num_epoch, batch, num_batch_train np.mean(loss_arr)))\n",
    "        \n",
    "        # tensorboard에 input & out & lable 저장 구문\n",
    "        label = fn_tonumpy(label)\n",
    "        input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
    "        output = fn_tonumpy(fn_class(output))\n",
    "        \n",
    "        writer_train.add_imgae('label', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "        writer_train.add_imgae('input', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "        writer_train.add_imgae('output', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "        \n",
    "        # Save the loss in tensorboard\n",
    "    writer_train.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "\n",
    "    \n",
    "    # Network validation\n",
    "    # backward가 없어, 사전에 막기 위해 torch.no_grad() 실시\n",
    "    with torch.no_grad() :\n",
    "        net.eval()               # Network validation 명시를 위해\n",
    "        loss_arr = []\n",
    "        \n",
    "        for batch, data in enumerate(loader_test, 1):\n",
    "                # forward pass\n",
    "                label = data['label'].to(device)\n",
    "                input = data['input'].to(device)    \n",
    "                \n",
    "                output = net(input)\n",
    "                \n",
    "                # 손실함수 계산\n",
    "                loss = fn_loss(output, lable)\n",
    "                \n",
    "                loss_arr += [loss.item()]\n",
    "                print(\"VALID: EPOCH %04d / %04d BATCH %04d / %04d| LOSS %.4f\" %\n",
    "                      (epoch,num_epoch, batch, num_batch_val np.mean(loss_arr)))\n",
    "        \n",
    "            # tensorboard에 input & out & lable 저장 구문\n",
    "            label = fn_tonumpy(label)\n",
    "            input = fn_tonumpy(fn_denorm(input)\n",
    "            output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "            writer_val.add_imgae('label', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "            writer_val.add_imgae('input', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "            writer_val.add_imgae('output', label, num_batch_train * (epoch -1) + batch, dataformats = 'NHWC')\n",
    "          \n",
    "        # Save the loss in tensorboard\n",
    "        writer_val.add_scalar('loss', np.mean(loss_arr), epoch)   \n",
    "        \n",
    "        # epoch이 다섯번씩 진행될 때 마다 네트워크를 저장하는 부분\n",
    "        if epochch % 5 == 0:\n",
    "            save(ckpt_dir=ckpt_dir, net =net, optim = optim, epoch= epoch)\n",
    "\n",
    "writer_train.close()           \n",
    "writer_val.close()\n",
    "                               \n",
    "                    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
